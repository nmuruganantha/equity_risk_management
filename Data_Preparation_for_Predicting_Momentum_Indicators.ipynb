{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers # type: ignore\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import requests\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "\n",
        "# Suppress FutureWarning from scikit-learn\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_dataframe_to_csv(df: pd.DataFrame, ticker: str, filename: str = None) -> bool:\n",
        "    \"\"\"\n",
        "    Saves a pandas DataFrame to a CSV file.\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        print(\"Error: Input is not a valid or non-empty DataFrame. Nothing to save.\")\n",
        "        return False\n",
        "\n",
        "    if filename is None:\n",
        "        filename = f\"{ticker}_market_data.csv\"\n",
        "\n",
        "    try:\n",
        "        # Save the DataFrame to a CSV file.\n",
        "        # The index (which is the date) is crucial, so we ensure it's saved.\n",
        "        df.to_csv(filename, index=True)\n",
        "        print(f\"\\nDataFrame successfully saved to '{filename}'\")\n",
        "        return True\n",
        "    except IOError as e:\n",
        "        # Handle specific file system errors\n",
        "        print(f\"\\nAn I/O error occurred while saving the file: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        # Handle any other unexpected errors\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = \"v0Y7rqjEfz0nBiixKBqJwLLgyFYbOUGA\"\n",
        "def get_historical_data_fmp(symbol, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetches historical price data from FMP API.\n",
        "    Calculates start_date based on period_in_quarters from current date.\n",
        "    Returns a DataFrame with 'open', 'high', 'low', 'close', 'volume' prices and a DatetimeIndex.\n",
        "    \"\"\"\n",
        "    print(f\"Fetching historical price data for {symbol} from {start_date} to {end_date} from FMP API...\")\n",
        "    \n",
        "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}?from={start_date}&to={end_date}&apikey={api_key}\"\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'historical' in data and data['historical']:\n",
        "            df = pd.DataFrame(data['historical'])\n",
        "            df['date'] = pd.to_datetime(df['date'])\n",
        "            df = df.set_index('date').sort_index()\n",
        "            # Ensure required columns are present and correctly named\n",
        "            df = df[['open', 'high', 'low', 'close', 'volume']]\n",
        "            print(f\"Successfully fetched {len(df)} historical price records from FMP.\")\n",
        "            return df\n",
        "        else:\n",
        "            print(f\"FMP API returned no historical price data for {symbol} in the specified period.\")\n",
        "            return pd.DataFrame()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching historical price data from FMP API: {e}\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_daily_return(df):\n",
        "    \"\"\"\n",
        "    Calculates the daily percentage return from the 'close' prices.\n",
        "    Adds a 'Daily_Return' column to the DataFrame.\n",
        "    \"\"\"\n",
        "    if 'close' not in df.columns:\n",
        "        print(\"Error: 'close' column not found for Daily_Return calculation.\")\n",
        "        df['Daily_Return'] = np.nan\n",
        "        return df\n",
        "    print(\"Calculating Daily_Return...\")\n",
        "    df['Daily_Return'] = df['close'].pct_change()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Relative Strength Index (RSI)**\n",
        "\n",
        "**RSI (Relative Strength Index)** is a **momentum indicator** used in technical analysis to measure the **speed and magnitude of recent price changes**. It helps identify **overbought or oversold conditions** in a stock or other asset.\n",
        "\n",
        "The standard calculation uses 14 periods (usually days):  \n",
        "\n",
        "RSI = 100 - (100 / (1 + RS)). \n",
        "\n",
        "RS = Average Gain over 14 periods / Average Loss over 14 periods. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Indicator Calculation ---\n",
        "def calculate_rsi(df, window=14):\n",
        "    delta = df['close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**MACD (Moving Average Convergence Divergence)**\n",
        "\n",
        "**MACD** is a popular **trend-following momentum indicator** used in technical analysis. It reveals changes in the strength, direction, momentum, and duration of a stock’s price trend.\n",
        "\n",
        "***Formula***\n",
        "\n",
        "Let:\n",
        "\n",
        "- **EMA₁₂** = 12-period Exponential Moving Average  \n",
        "- **EMA₂₆** = 26-period Exponential Moving Average. \n",
        "\n",
        "MACD Line     = EMA₁₂ - EMA₂₆. \n",
        "\n",
        "Signal Line   = 9-period EMA of the MACD Line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_macd(df, short_window=12, long_window=26, signal_window=9):\n",
        "    exp1 = df['close'].ewm(span=short_window, adjust=False).mean()\n",
        "    exp2 = df['close'].ewm(span=long_window, adjust=False).mean()\n",
        "    df['MACD'] = exp1 - exp2\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Momentum Indicator**\n",
        "\n",
        "The Momentum Indicator is a simple yet effective technical analysis tool that measures the **rate of change** of a stock's price. It helps identify the strength of a trend and potential reversals.\n",
        "\n",
        "***Formula***\n",
        "\n",
        "Momentum = Current Closing Price - Closing Price  n  periods ago"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_momentum(df, window=1):\n",
        "    df['Momentum'] = df['close'].diff(window)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**On-Balance Volume (OBV)**\n",
        "\n",
        "On-Balance Volume (OBV) is a technical analysis indicator that relates volume to price movement. It measures cumulative buying and selling pressure by adding volume on up days and subtracting it on down days.\n",
        "\n",
        "***OBV Formula***\n",
        "\n",
        "Let:\n",
        "\n",
        "- OBVₜ = OBV on day t\n",
        "- Volumeₜ = trading volume on day t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_obv(df):\n",
        "    df['OBV'] = (np.sign(df['close'].diff()) * df['volume']).fillna(0).cumsum()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Average True Range (ATR)**\n",
        "\n",
        "ATR (Average True Range) is a technical analysis indicator that measures market volatility. It tells how much an asset typically moves (in price) during a given time period.\n",
        "\n",
        "***Formula***\n",
        "\n",
        "True Range (TR):\n",
        "\n",
        "The True Range (TR) for a given day is the maximum of the following:  \n",
        "\n",
        "TR = max(\n",
        "High_t - Low_t,\n",
        "|High_t - Close_{t-1}|,\n",
        "|Low_t - Close_{t-1}|\n",
        "). \n",
        "\n",
        "***Average True Range (ATR):***\n",
        "\n",
        "ATR is a moving average (commonly 14 periods) of the True Range:  \n",
        "ATR_t = (1/n) * sum(TR_{t-i}) for i = 0 to n-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_atr(df, window=14):\n",
        "    high_low = df['high'] - df['low']\n",
        "    high_close = np.abs(df['high'] - df['close'].shift())\n",
        "    low_close = np.abs(df['low'] - df['close'].shift())\n",
        "    # Combine the three True Range components into one DataFrame:\n",
        "    # 1. high_low: High - Low (intra-day range)\n",
        "    # 2. high_close: |High - Previous Close| (gap up/down possibility)\n",
        "    # 3. low_close: |Low - Previous Close| (gap down possibility)\n",
        "    # Then take the row-wise max to compute the True Range for each day\n",
        "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "    df['ATR'] = tr.ewm(span=window, adjust=False).mean()\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_fundamental_data_fmp(symbol, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetches fundamental data (Income Statement, Key Metrics) from FMP API\n",
        "    and calculates EPS Growth, Revenue Growth, and ROE.\n",
        "    Returns a DataFrame with fundamental metrics and a DatetimeIndex.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Fetching fundamental data for {symbol} from {start_date} to {end_date} from FMP API...\")\n",
        "\n",
        "    fundamental_df_list = []\n",
        "\n",
        "    try:\n",
        "        # Fetch Income Statements (quarterly)\n",
        "        income_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{symbol}?period=quarter&apikey={api_key}\"\n",
        "        income_response = requests.get(income_url)\n",
        "        income_response.raise_for_status()\n",
        "        income_statements = income_response.json()\n",
        "        \n",
        "        income_df = pd.DataFrame(income_statements)\n",
        "        if not income_df.empty:\n",
        "            income_df['date'] = pd.to_datetime(income_df['date'])\n",
        "            income_df = income_df.set_index('date').sort_index()\n",
        "            \n",
        "            # Calculate Revenue Growth (Year-over-Year Quarterly)\n",
        "            # Ensure 'revenue' column exists\n",
        "            if 'revenue' in income_df.columns:\n",
        "                income_df['Revenue_Growth'] = income_df['revenue'].pct_change(periods=4) # Compare to same quarter last year\n",
        "            else:\n",
        "                income_df['Revenue_Growth'] = np.nan\n",
        "                print(\"Warning: 'revenue' column not found in income statements for Revenue_Growth calculation.\")\n",
        "\n",
        "            # Calculate EPS Growth (Year-over-Year Quarterly)\n",
        "            # Ensure 'eps' column exists\n",
        "            if 'eps' in income_df.columns:\n",
        "                income_df['EPS_Growth'] = income_df['eps'].pct_change(periods=4) # Compare to same quarter last year\n",
        "            else:\n",
        "                income_df['EPS_Growth'] = np.nan\n",
        "                print(\"Warning: 'eps' column not found in income statements for EPS_Growth calculation.\")\n",
        "            \n",
        "            income_df = income_df[['Revenue_Growth', 'EPS_Growth']]\n",
        "            fundamental_df_list.append(income_df)\n",
        "        else:\n",
        "            print(\"No income statements found.\")\n",
        "\n",
        "        # Fetch Key Metrics (quarterly) for ROE\n",
        "        key_metrics_url = f\"https://financialmodelingprep.com/api/v3/key-metrics/{symbol}?period=quarter&apikey={api_key}\"\n",
        "        key_metrics_response = requests.get(key_metrics_url)\n",
        "        key_metrics_response.raise_for_status()\n",
        "        key_metrics = key_metrics_response.json()\n",
        "\n",
        "        key_metrics_df = pd.DataFrame(key_metrics)\n",
        "        if not key_metrics_df.empty:\n",
        "            key_metrics_df['date'] = pd.to_datetime(key_metrics_df['date'])\n",
        "            key_metrics_df = key_metrics_df.set_index('date').sort_index()\n",
        "            # Ensure 'roe' column exists\n",
        "            if 'roe' in key_metrics_df.columns:\n",
        "                key_metrics_df['ROE'] = key_metrics_df['roe']\n",
        "            else:\n",
        "                key_metrics_df['ROE'] = np.nan\n",
        "                print(\"Warning: 'roe' column not found in key metrics for ROE.\")\n",
        "            key_metrics_df = key_metrics_df[['ROE']]\n",
        "            fundamental_df_list.append(key_metrics_df)\n",
        "        else:\n",
        "            print(\"No key metrics found.\")\n",
        "\n",
        "        if not fundamental_df_list:\n",
        "            print(\"No fundamental data could be fetched or processed.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Merge all fundamental dataframes\n",
        "        merged_fundamental_df = pd.concat(fundamental_df_list, axis=1).sort_index()\n",
        "        # Filter by date range\n",
        "        merged_fundamental_df = merged_fundamental_df[(merged_fundamental_df.index >= start_date) & (merged_fundamental_df.index <= end_date)]\n",
        "        merged_fundamental_df.index.name = 'date'\n",
        "        print(f\"Successfully fetched and processed {len(merged_fundamental_df)} fundamental records from FMP.\")\n",
        "        return merged_fundamental_df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching fundamental data from FMP API: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during fundamental data processing: {e}\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dataframe(symbol, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Prepares a DataFrame with historical price data, calculated technical indicators,\n",
        "    and merged fundamental data. The date will be set as the DataFrame's index.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Preparing DataFrame for {symbol} from {start_date} to {end_date} ---\")\n",
        "    # Pass the api_key to the data fetching functions\n",
        "    price_data = get_historical_data_fmp(symbol, start_date, end_date)\n",
        "    if price_data.empty:\n",
        "        print(\"Error: No historical price data found.\")\n",
        "        return None\n",
        "\n",
        "    df = price_data.copy()\n",
        "    print(f\"Initial price_data shape: {df.shape}\")\n",
        "\n",
        "    # Calculate technical indicators\n",
        "    df = calculate_rsi(df)\n",
        "    df = calculate_macd(df)\n",
        "    df = calculate_momentum(df)\n",
        "    df = calculate_obv(df)\n",
        "    df = calculate_atr(df)\n",
        "    df = calculate_daily_return(df)\n",
        "    print(f\"DataFrame shape after technical indicator calculation: {df.shape}\")\n",
        "\n",
        "    # Drop NaNs that result from initial technical indicator calculations\n",
        "    # This is crucial before merging fundamental data to ensure proper alignment.\n",
        "    df.dropna(inplace=True)\n",
        "    print(f\"DataFrame shape after dropping NaNs from indicator calculation: {df.shape}\")\n",
        "    if df.empty:\n",
        "        print(\"Error: DataFrame is empty after calculating indicators and dropping NaNs.\")\n",
        "        return None\n",
        "    \n",
        "    # Merge with fundamental data (forward-fill)\n",
        "    # Pass the api_key to the data fetching functions\n",
        "    fundamental_df = get_fundamental_data_fmp(symbol, start_date, end_date)\n",
        "    if fundamental_df.empty:\n",
        "        print(\"Error: No fundamental data fetched. This might lead to empty fundamental columns.\")\n",
        "        return None \n",
        "    #save_dataframe_to_csv(fundamental_df, \"cache/\" + symbol + \"_fundamental\")  # Save the fundamental DataFrame to CSV\n",
        "    print(f\"Fundamental data shape: {fundamental_df.shape}\")\n",
        "    if fundamental_df.empty:\n",
        "        print(\"Warning: No fundamental data generated by FMP API. This might lead to empty fundamental columns.\")\n",
        "\n",
        "    df = df.reset_index().rename(columns={\"index\": \"date\"})\n",
        "    fundamental_df = fundamental_df.reset_index().rename(columns={\"index\": \"date\"})\n",
        "    \n",
        "    df_merged = pd.merge(df, fundamental_df, on='date', how='outer')    \n",
        "    df_merged.set_index('date', inplace=True)\n",
        "    \n",
        "    print(f\"DataFrame shape after left merge with fundamental data: {df_merged.shape}\")\n",
        "    print(\"NaN count in fundamental columns after merge (before ffill):\")\n",
        "    if not df_merged.empty:\n",
        "        for col in ['EPS_Growth', 'Revenue_Growth', 'ROE']:\n",
        "            if col in df_merged.columns:\n",
        "                print(f\"  {col}: {df_merged[col].isna().sum()} NaNs\")\n",
        "\n",
        "    df_filled = df_merged.fillna(method='ffill').dropna()\n",
        "    print(f\"DataFrame shape after forward-fill: {df_filled.shape}\")\n",
        "    print(\"NaN count in fundamental columns after ffill (before final dropna):\")\n",
        "    if not df_filled.empty:\n",
        "        for col in ['EPS_Growth', 'Revenue_Growth', 'ROE']:\n",
        "            if col in df_filled.columns:\n",
        "                print(f\"  {col}: {df_filled[col].isna().sum()} NaNs\")\n",
        "\n",
        "    # The final dropna() is crucial for removing any leading NaNs that couldn't be ffilled\n",
        "    # (e.g., if fundamental data starts much later than price data, or if there are initial NaNs\n",
        "    # in technical indicators that were not dropped previously).\n",
        "    df_final = df_filled.dropna()\n",
        "    df_final.drop(columns=['open', 'high', 'low'], inplace=True)    \n",
        "    save_dataframe_to_csv(df_final, \"data/\" + symbol)  # Save the merged DataFrame to CSV\n",
        "    print(f\"DataFrame shape after dropping remaining NaNs: {df_final.shape}\")\n",
        "\n",
        "    if df_final.empty:\n",
        "        print(\"Error: DataFrame is empty after merging, forward-filling, and dropping NaNs. This might be due to insufficient initial fundamental data or too many leading NaNs.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"DataFrame prepared with {len(df_final)} rows and {len(df_final.columns)} columns.\")\n",
        "    print(f\"DataFrame index name: {df_final.index.name}\")\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_training_testing_datasets(df, lookback_window=30, predict_horizon=1):\n",
        "    \"\"\"\n",
        "    Creates training and testing datasets (X, Y) from a prepared DataFrame,\n",
        "    applying scaling to both inputs and outputs.\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(\"Error: Input DataFrame is empty or None.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    print(f\"\\n--- Creating Training/Testing Datasets ---\")\n",
        "\n",
        "    # Select features (inputs) and targets (outputs)\n",
        "    input_features = [\n",
        "        'RSI', 'MACD', 'MACD_Signal', 'Momentum', 'OBV', 'ATR',\n",
        "        'EPS_Growth', 'Revenue_Growth', 'ROE'\n",
        "    ]\n",
        "    output_targets = ['RSI', 'MACD', 'close'] # 'close' here refers to the future close price\n",
        "\n",
        "    # Ensure all required columns exist after calculations and merges\n",
        "    missing_cols = [col for col in input_features + output_targets if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        print(f\"Error: Missing required columns in DataFrame: {missing_cols}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Normalize indicators\n",
        "    scaler_input = MinMaxScaler()\n",
        "    scaler_output = MinMaxScaler()\n",
        "\n",
        "    # Create input and output sequences\n",
        "    X, Y = [], []\n",
        "    # The range for `i` must ensure that `i + lookback_window + predict_horizon - 1`\n",
        "    # does not exceed the length of the DataFrame.\n",
        "    # The last valid index for `Y` will be `len(df) - 1`.\n",
        "    # So, `i + lookback_window + predict_horizon - 1 <= len(df) - 1`\n",
        "    # which simplifies to `i <= len(df) - lookback_window - predict_horizon`.\n",
        "    for i in range(len(df) - lookback_window - predict_horizon + 1):\n",
        "        # Input: `lookback_window` days of selected indicators\n",
        "        X.append(df[input_features].iloc[i : i + lookback_window].values)\n",
        "        # Output: `predict_horizon` day's RSI, MACD, and 'close' price\n",
        "        Y.append(df[output_targets].iloc[i + lookback_window + predict_horizon - 1].values)\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    if X.size == 0 or Y.size == 0:\n",
        "        print(f\"Not enough data after windowing with lookback_window={lookback_window} and predict_horizon={predict_horizon}.\")\n",
        "        print(\"Adjust lookback_window or predict_horizon, or ensure sufficient input data.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Apply scaling to input features\n",
        "    # Reshape X to (n_samples * lookback_window, n_features) for scaling\n",
        "    original_shape_X = X.shape\n",
        "    X_reshaped_for_scaling = X.reshape(-1, original_shape_X[-1])\n",
        "    X_scaled_reshaped = scaler_input.fit_transform(X_reshaped_for_scaling)\n",
        "    X_scaled = X_scaled_reshaped.reshape(original_shape_X)\n",
        "\n",
        "    # Apply scaling to output targets\n",
        "    Y_scaled = scaler_output.fit_transform(Y)\n",
        "\n",
        "    print(f\"Created X_scaled with shape: {X_scaled.shape}\")\n",
        "    print(f\"Created Y_scaled with shape: {Y_scaled.shape}\")\n",
        "\n",
        "    return X_scaled, Y_scaled, scaler_input, scaler_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Preparing DataFrame for AAPL from 2010-01-01 to 2024-12-31 ---\n",
            "Fetching historical price data for AAPL from 2010-01-01 to 2024-12-31 from FMP API...\n",
            "Successfully fetched 3774 historical price records from FMP.\n",
            "Initial price_data shape: (3774, 5)\n",
            "Calculating Daily_Return...\n",
            "DataFrame shape after technical indicator calculation: (3774, 12)\n",
            "DataFrame shape after dropping NaNs from indicator calculation: (3761, 12)\n",
            "Fetching fundamental data for AAPL from 2010-01-01 to 2024-12-31 from FMP API...\n",
            "Successfully fetched and processed 60 fundamental records from FMP.\n",
            "Fundamental data shape: (60, 3)\n",
            "DataFrame shape after left merge with fundamental data: (3821, 15)\n",
            "NaN count in fundamental columns after merge (before ffill):\n",
            "  EPS_Growth: 3761 NaNs\n",
            "  Revenue_Growth: 3761 NaNs\n",
            "  ROE: 3761 NaNs\n",
            "DataFrame shape after forward-fill: (3776, 15)\n",
            "NaN count in fundamental columns after ffill (before final dropna):\n",
            "  EPS_Growth: 0 NaNs\n",
            "  Revenue_Growth: 0 NaNs\n",
            "  ROE: 0 NaNs\n",
            "\n",
            "DataFrame successfully saved to 'data/AAPL_market_data.csv'\n",
            "DataFrame shape after dropping remaining NaNs: (3776, 12)\n",
            "DataFrame prepared with 3776 rows and 12 columns.\n",
            "DataFrame index name: date\n",
            "\n",
            "--- First few rows of Prepared DataFrame ---\n",
            "            close       volume        RSI      MACD  MACD_Signal  Momentum  \\\n",
            "date                                                                         \n",
            "2010-03-27   8.25  640875200.0  70.873786  0.207522     0.198145      0.16   \n",
            "2010-03-29   8.30  540744400.0  68.085106  0.213018     0.201120      0.05   \n",
            "2010-03-30   8.42  527310000.0  69.696970  0.224470     0.205790      0.12   \n",
            "2010-03-31   8.39  430659600.0  67.000000  0.228491     0.210330     -0.03   \n",
            "2010-04-01   8.43  603145200.0  67.000000  0.232228     0.214710      0.04   \n",
            "\n",
            "                     OBV       ATR  Daily_Return  Revenue_Growth  EPS_Growth  \\\n",
            "date                                                                           \n",
            "2010-03-27  8.900610e+09  0.147949      0.019778        0.486019    1.484472   \n",
            "2010-03-29  9.441355e+09  0.141556      0.006061        0.486019    1.484472   \n",
            "2010-03-30  9.968665e+09  0.146682      0.014458        0.486019    1.484472   \n",
            "2010-03-31  9.538005e+09  0.137791     -0.003563        0.486019    1.484472   \n",
            "2010-04-01  1.014115e+10  0.148752      0.004768        0.486019    1.484472   \n",
            "\n",
            "                 ROE  \n",
            "date                  \n",
            "2010-03-27  0.078123  \n",
            "2010-03-29  0.078123  \n",
            "2010-03-30  0.078123  \n",
            "2010-03-31  0.078123  \n",
            "2010-04-01  0.078123  \n",
            "\n",
            "--- Last few rows of Prepared DataFrame ---\n",
            "             close      volume        RSI      MACD  MACD_Signal  Momentum  \\\n",
            "date                                                                         \n",
            "2024-12-26  259.02  27262983.0  76.812081  6.288037     5.552329      0.82   \n",
            "2024-12-27  255.59  42355321.0  69.300636  6.126376     5.667138     -3.43   \n",
            "2024-12-28  255.59  42355321.0  69.300636  6.126376     5.667138     -3.43   \n",
            "2024-12-30  252.20  35557542.0  58.382036  5.659475     5.665606     -3.39   \n",
            "2024-12-31  250.42  39480718.0  53.982567  5.087179     5.549920     -1.78   \n",
            "\n",
            "                     OBV       ATR  Daily_Return  Revenue_Growth  EPS_Growth  \\\n",
            "date                                                                           \n",
            "2024-12-26  1.776578e+10  4.001121      0.003176        0.060694   -0.340136   \n",
            "2024-12-27  1.772342e+10  4.262305     -0.013242        0.060694   -0.340136   \n",
            "2024-12-28  1.772342e+10  4.262305     -0.013242        0.039515    0.100457   \n",
            "2024-12-30  1.768787e+10  4.339331     -0.013263        0.039515    0.100457   \n",
            "2024-12-31  1.764839e+10  4.274087     -0.007058        0.039515    0.100457   \n",
            "\n",
            "                 ROE  \n",
            "date                  \n",
            "2024-12-26  0.258753  \n",
            "2024-12-27  0.258753  \n",
            "2024-12-28  0.544204  \n",
            "2024-12-30  0.544204  \n",
            "2024-12-31  0.544204  \n",
            "\n",
            "Prepared DataFrame shape: (3776, 12)\n",
            "\n",
            "--- Creating Training/Testing Datasets ---\n",
            "Created X_scaled with shape: (3746, 30, 9)\n",
            "Created Y_scaled with shape: (3746, 3)\n",
            "\n",
            "Successfully created scaled datasets and scalers.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    symbol_to_process = \"AAPL\" # Example symbol\n",
        "    end_date = \"2024-12-31\"  # Example end date\n",
        "    start_date = \"2010-01-01\"  # Example start date\n",
        "\n",
        "    # Step 1: Prepare the DataFrame\n",
        "    # Pass the API key to prepare_dataframe\n",
        "    prepared_df = prepare_dataframe(symbol_to_process, start_date, end_date)\n",
        "\n",
        "    if prepared_df is not None:\n",
        "        print(\"\\n--- First few rows of Prepared DataFrame ---\")\n",
        "        print(prepared_df.head())\n",
        "        print(\"\\n--- Last few rows of Prepared DataFrame ---\")\n",
        "        print(prepared_df.tail())\n",
        "        print(f\"\\nPrepared DataFrame shape: {prepared_df.shape}\")\n",
        "\n",
        "        # Step 2: Create training and testing datasets\n",
        "        X_scaled, Y_scaled, scaler_input, scaler_output = create_training_testing_datasets(\n",
        "            prepared_df,\n",
        "            lookback_window=30,\n",
        "            predict_horizon=1\n",
        "        )\n",
        "\n",
        "        if X_scaled is not None:\n",
        "            print(\"\\nSuccessfully created scaled datasets and scalers.\")\n",
        "            # You can now proceed with splitting into train/test sets and model training\n",
        "            # from sklearn.model_selection import train_test_split\n",
        "            # X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_scaled, test_size=0.2, random_state=42)\n",
        "            # print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
        "            # print(f\"X_test shape: {X_test.shape}, Y_test shape: {Y_test.shape}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning-python-3.10_numpy1.26.4-M4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
