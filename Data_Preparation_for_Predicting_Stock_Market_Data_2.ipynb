{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 718,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers # type: ignore\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import requests\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "\n",
        "# Suppress FutureWarning from scikit-learn\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 719,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_dataframe_to_csv(df: pd.DataFrame, ticker: str, filename: str = None) -> bool:\n",
        "    \"\"\"\n",
        "    Saves a pandas DataFrame to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame to save.\n",
        "        ticker (str): The stock ticker symbol, used for the default filename.\n",
        "        filename (str, optional): The desired filename. If None, a default\n",
        "                                  filename is generated (e.g., 'AAPL_combined_data_YYYY-MM-DD.csv').\n",
        "                                  Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the file was saved successfully, False otherwise.\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        print(\"Error: Input is not a valid or non-empty DataFrame. Nothing to save.\")\n",
        "        return False\n",
        "\n",
        "    if filename is None:\n",
        "        # Create a dynamic default filename if one isn't provided.\n",
        "        # This prevents overwriting previous files.\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d')\n",
        "        filename = f\"{ticker}_combined_data_{timestamp}.csv\"\n",
        "\n",
        "    try:\n",
        "        # Save the DataFrame to a CSV file.\n",
        "        # The index (which is the date) is crucial, so we ensure it's saved.\n",
        "        df.to_csv(filename, index=True)\n",
        "        print(f\"\\nDataFrame successfully saved to '{filename}'\")\n",
        "        return True\n",
        "    except IOError as e:\n",
        "        # Handle specific file system errors\n",
        "        print(f\"\\nAn I/O error occurred while saving the file: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        # Handle any other unexpected errors\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 720,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = \"v0Y7rqjEfz0nBiixKBqJwLLgyFYbOUGA\"\n",
        "def get_historical_data_fmp(symbol, period_in_quarters):\n",
        "    \"\"\"\n",
        "    Fetches historical price data from FMP API.\n",
        "    Calculates start_date based on period_in_quarters from current date.\n",
        "    Returns a DataFrame with 'open', 'high', 'low', 'close', 'volume' prices and a DatetimeIndex.\n",
        "    \"\"\"\n",
        "    end_date = datetime.now()\n",
        "    # Approximate days per quarter: 365.25 / 4 = 91.3125 days. Using 91.3125 for better accuracy.\n",
        "    start_date = end_date - timedelta(days=period_in_quarters * 91.3125)\n",
        "\n",
        "    print(f\"Fetching historical price data for {symbol} from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')} from FMP API...\")\n",
        "    \n",
        "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}?from={start_date.strftime('%Y-%m-%d')}&to={end_date.strftime('%Y-%m-%d')}&apikey={api_key}\"\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'historical' in data and data['historical']:\n",
        "            df = pd.DataFrame(data['historical'])\n",
        "            df['date'] = pd.to_datetime(df['date'])\n",
        "            df = df.set_index('date').sort_index()\n",
        "            # Ensure required columns are present and correctly named\n",
        "            df = df[['open', 'high', 'low', 'close', 'volume']]\n",
        "            print(f\"Successfully fetched {len(df)} historical price records from FMP.\")\n",
        "            return df\n",
        "        else:\n",
        "            print(f\"FMP API returned no historical price data for {symbol} in the specified period.\")\n",
        "            return pd.DataFrame()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching historical price data from FMP API: {e}\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Relative Strength Index (RSI)**\n",
        "\n",
        "**RSI (Relative Strength Index)** is a **momentum indicator** used in technical analysis to measure the **speed and magnitude of recent price changes**. It helps identify **overbought or oversold conditions** in a stock or other asset.\n",
        "\n",
        "The standard calculation uses 14 periods (usually days):  \n",
        "\n",
        "RSI = 100 - (100 / (1 + RS)). \n",
        "\n",
        "RS = Average Gain over 14 periods / Average Loss over 14 periods. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 721,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Indicator Calculation ---\n",
        "def calculate_rsi(df, window=14):\n",
        "    delta = df['close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**MACD (Moving Average Convergence Divergence)**\n",
        "\n",
        "**MACD** is a popular **trend-following momentum indicator** used in technical analysis. It reveals changes in the strength, direction, momentum, and duration of a stock’s price trend.\n",
        "\n",
        "***Formula***\n",
        "\n",
        "Let:\n",
        "\n",
        "- **EMA₁₂** = 12-period Exponential Moving Average  \n",
        "- **EMA₂₆** = 26-period Exponential Moving Average. \n",
        "\n",
        "MACD Line     = EMA₁₂ - EMA₂₆. \n",
        "\n",
        "Signal Line   = 9-period EMA of the MACD Line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 722,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_macd(df, short_window=12, long_window=26, signal_window=9):\n",
        "    exp1 = df['close'].ewm(span=short_window, adjust=False).mean()\n",
        "    exp2 = df['close'].ewm(span=long_window, adjust=False).mean()\n",
        "    df['MACD'] = exp1 - exp2\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Momentum Indicator**\n",
        "\n",
        "The Momentum Indicator is a simple yet effective technical analysis tool that measures the **rate of change** of a stock's price. It helps identify the strength of a trend and potential reversals.\n",
        "\n",
        "***Formula***\n",
        "\n",
        "Momentum = Current Closing Price - Closing Price  n  periods ago"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 723,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_momentum(df, window=1):\n",
        "    df['Momentum'] = df['close'].diff(window)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**On-Balance Volume (OBV)**\n",
        "\n",
        "On-Balance Volume (OBV) is a technical analysis indicator that relates volume to price movement. It measures cumulative buying and selling pressure by adding volume on up days and subtracting it on down days.\n",
        "\n",
        "***OBV Formula***\n",
        "\n",
        "Let:\n",
        "\n",
        "- OBVₜ = OBV on day t\n",
        "- Volumeₜ = trading volume on day t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 724,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_obv(df):\n",
        "    df['OBV'] = (np.sign(df['close'].diff()) * df['volume']).fillna(0).cumsum()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Average True Range (ATR)**\n",
        "\n",
        "ATR (Average True Range) is a technical analysis indicator that measures market volatility. It tells how much an asset typically moves (in price) during a given time period.\n",
        "\n",
        "***Formula***\n",
        "\n",
        "True Range (TR):\n",
        "\n",
        "The True Range (TR) for a given day is the maximum of the following:  \n",
        "\n",
        "TR = max(\n",
        "High_t - Low_t,\n",
        "|High_t - Close_{t-1}|,\n",
        "|Low_t - Close_{t-1}|\n",
        "). \n",
        "\n",
        "***Average True Range (ATR):***\n",
        "\n",
        "ATR is a moving average (commonly 14 periods) of the True Range:  \n",
        "ATR_t = (1/n) * sum(TR_{t-i}) for i = 0 to n-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 725,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_atr(df, window=14):\n",
        "    high_low = df['high'] - df['low']\n",
        "    high_close = np.abs(df['high'] - df['close'].shift())\n",
        "    low_close = np.abs(df['low'] - df['close'].shift())\n",
        "    # Combine the three True Range components into one DataFrame:\n",
        "    # 1. high_low: High - Low (intra-day range)\n",
        "    # 2. high_close: |High - Previous Close| (gap up/down possibility)\n",
        "    # 3. low_close: |Low - Previous Close| (gap down possibility)\n",
        "    # Then take the row-wise max to compute the True Range for each day\n",
        "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "    df['ATR'] = tr.ewm(span=window, adjust=False).mean()\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 726,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_fundamental_data_fmp(symbol, period_in_quarters):\n",
        "    \"\"\"\n",
        "    Fetches fundamental data (Income Statement, Key Metrics) from FMP API\n",
        "    and calculates EPS Growth, Revenue Growth, and ROE.\n",
        "    Returns a DataFrame with fundamental metrics and a DatetimeIndex.\n",
        "    \"\"\"\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=period_in_quarters * 91.3125)\n",
        "\n",
        "    print(f\"Fetching fundamental data for {symbol} from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')} from FMP API...\")\n",
        "\n",
        "    fundamental_df_list = []\n",
        "\n",
        "    try:\n",
        "        # Fetch Income Statements (quarterly)\n",
        "        income_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{symbol}?period=quarter&limit={period_in_quarters * 2}&apikey={api_key}\"\n",
        "        income_response = requests.get(income_url)\n",
        "        income_response.raise_for_status()\n",
        "        income_statements = income_response.json()\n",
        "        \n",
        "        income_df = pd.DataFrame(income_statements)\n",
        "        if not income_df.empty:\n",
        "            income_df['date'] = pd.to_datetime(income_df['date'])\n",
        "            income_df = income_df.set_index('date').sort_index()\n",
        "            \n",
        "            # Calculate Revenue Growth (Year-over-Year Quarterly)\n",
        "            # Ensure 'revenue' column exists\n",
        "            if 'revenue' in income_df.columns:\n",
        "                income_df['Revenue_Growth'] = income_df['revenue'].pct_change(periods=4) # Compare to same quarter last year\n",
        "            else:\n",
        "                income_df['Revenue_Growth'] = np.nan\n",
        "                print(\"Warning: 'revenue' column not found in income statements for Revenue_Growth calculation.\")\n",
        "\n",
        "            # Calculate EPS Growth (Year-over-Year Quarterly)\n",
        "            # Ensure 'eps' column exists\n",
        "            if 'eps' in income_df.columns:\n",
        "                income_df['EPS_Growth'] = income_df['eps'].pct_change(periods=4) # Compare to same quarter last year\n",
        "            else:\n",
        "                income_df['EPS_Growth'] = np.nan\n",
        "                print(\"Warning: 'eps' column not found in income statements for EPS_Growth calculation.\")\n",
        "            \n",
        "            income_df = income_df[['Revenue_Growth', 'EPS_Growth']]\n",
        "            fundamental_df_list.append(income_df)\n",
        "        else:\n",
        "            print(\"No income statements found.\")\n",
        "\n",
        "        # Fetch Key Metrics (quarterly) for ROE\n",
        "        key_metrics_url = f\"https://financialmodelingprep.com/api/v3/key-metrics/{symbol}?period=quarter&limit={period_in_quarters * 2}&apikey={api_key}\"\n",
        "        key_metrics_response = requests.get(key_metrics_url)\n",
        "        key_metrics_response.raise_for_status()\n",
        "        key_metrics = key_metrics_response.json()\n",
        "\n",
        "        key_metrics_df = pd.DataFrame(key_metrics)\n",
        "        if not key_metrics_df.empty:\n",
        "            key_metrics_df['date'] = pd.to_datetime(key_metrics_df['date'])\n",
        "            key_metrics_df = key_metrics_df.set_index('date').sort_index()\n",
        "            # Ensure 'roe' column exists\n",
        "            if 'roe' in key_metrics_df.columns:\n",
        "                key_metrics_df['ROE'] = key_metrics_df['roe']\n",
        "            else:\n",
        "                key_metrics_df['ROE'] = np.nan\n",
        "                print(\"Warning: 'roe' column not found in key metrics for ROE.\")\n",
        "            key_metrics_df = key_metrics_df[['ROE']]\n",
        "            fundamental_df_list.append(key_metrics_df)\n",
        "        else:\n",
        "            print(\"No key metrics found.\")\n",
        "\n",
        "        if not fundamental_df_list:\n",
        "            print(\"No fundamental data could be fetched or processed.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Merge all fundamental dataframes\n",
        "        merged_fundamental_df = pd.concat(fundamental_df_list, axis=1).sort_index()\n",
        "        # Filter by date range\n",
        "        merged_fundamental_df = merged_fundamental_df[(merged_fundamental_df.index >= start_date) & (merged_fundamental_df.index <= end_date)]\n",
        "        merged_fundamental_df.index.name = 'date'\n",
        "        print(f\"Successfully fetched and processed {len(merged_fundamental_df)} fundamental records from FMP.\")\n",
        "        return merged_fundamental_df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching fundamental data from FMP API: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during fundamental data processing: {e}\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dataframe(symbol, period_in_quarters):\n",
        "    \"\"\"\n",
        "    Prepares a DataFrame with historical price data, calculated technical indicators,\n",
        "    and merged fundamental data. The date will be set as the DataFrame's index.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Preparing DataFrame for {symbol} for {period_in_quarters} quarters ---\")\n",
        "    # Pass the api_key to the data fetching functions\n",
        "    price_data = get_historical_data_fmp(symbol, period_in_quarters)\n",
        "    if price_data.empty:\n",
        "        print(\"Error: No historical price data found.\")\n",
        "        return None\n",
        "\n",
        "    df = price_data.copy()\n",
        "    print(f\"Initial price_data shape: {df.shape}\")\n",
        "\n",
        "    # Calculate technical indicators\n",
        "    df = calculate_rsi(df)\n",
        "    df = calculate_macd(df)\n",
        "    df = calculate_momentum(df)\n",
        "    df = calculate_obv(df)\n",
        "    df = calculate_atr(df)\n",
        "    print(f\"DataFrame shape after technical indicator calculation: {df.shape}\")\n",
        "\n",
        "    # Drop NaNs that result from initial technical indicator calculations\n",
        "    # This is crucial before merging fundamental data to ensure proper alignment.\n",
        "    df.dropna(inplace=True)\n",
        "    print(f\"DataFrame shape after dropping NaNs from indicator calculation: {df.shape}\")\n",
        "    if df.empty:\n",
        "        print(\"Error: DataFrame is empty after calculating indicators and dropping NaNs.\")\n",
        "        return None\n",
        "    \n",
        "    # Merge with fundamental data (forward-fill)\n",
        "    # Pass the api_key to the data fetching functions\n",
        "    fundamental_df = get_fundamental_data_fmp(symbol, period_in_quarters)\n",
        "    print(f\"Fundamental data shape: {fundamental_df.shape}\")\n",
        "    if fundamental_df.empty:\n",
        "        print(\"Warning: No fundamental data generated by FMP API. This might lead to empty fundamental columns.\")\n",
        "\n",
        "    df = df.reset_index().rename(columns={\"index\": \"date\"})\n",
        "    fundamental_df = fundamental_df.reset_index().rename(columns={\"index\": \"date\"})\n",
        "    \n",
        "    df_merged = pd.merge(df, fundamental_df, on='date', how='outer')    \n",
        "    df_merged.set_index('date', inplace=True)\n",
        "    \n",
        "    print(f\"DataFrame shape after left merge with fundamental data: {df_merged.shape}\")\n",
        "    print(\"NaN count in fundamental columns after merge (before ffill):\")\n",
        "    if not df_merged.empty:\n",
        "        for col in ['EPS_Growth', 'Revenue_Growth', 'ROE']:\n",
        "            if col in df_merged.columns:\n",
        "                print(f\"  {col}: {df_merged[col].isna().sum()} NaNs\")\n",
        "\n",
        "    df_filled = df_merged.fillna(method='ffill').dropna()\n",
        "\n",
        "    save_dataframe_to_csv(df_filled, \"cache/\" + symbol + \"_merged\")  # Save the merged DataFrame to CSV\n",
        "    print(f\"DataFrame shape after forward-fill: {df_filled.shape}\")\n",
        "    print(\"NaN count in fundamental columns after ffill (before final dropna):\")\n",
        "    if not df_filled.empty:\n",
        "        for col in ['EPS_Growth', 'Revenue_Growth', 'ROE']:\n",
        "            if col in df_filled.columns:\n",
        "                print(f\"  {col}: {df_filled[col].isna().sum()} NaNs\")\n",
        "\n",
        "    # The final dropna() is crucial for removing any leading NaNs that couldn't be ffilled\n",
        "    # (e.g., if fundamental data starts much later than price data, or if there are initial NaNs\n",
        "    # in technical indicators that were not dropped previously).\n",
        "    df_final = df_filled.dropna()\n",
        "    print(f\"DataFrame shape after dropping remaining NaNs: {df_final.shape}\")\n",
        "\n",
        "    if df_final.empty:\n",
        "        print(\"Error: DataFrame is empty after merging, forward-filling, and dropping NaNs. This might be due to insufficient initial fundamental data or too many leading NaNs.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"DataFrame prepared with {len(df_final)} rows and {len(df_final.columns)} columns.\")\n",
        "    print(f\"DataFrame index name: {df_final.index.name}\")\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_training_testing_datasets(df, lookback_window=30, predict_horizon=1):\n",
        "    \"\"\"\n",
        "    Creates training and testing datasets (X, Y) from a prepared DataFrame,\n",
        "    applying scaling to both inputs and outputs.\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(\"Error: Input DataFrame is empty or None.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    print(f\"\\n--- Creating Training/Testing Datasets ---\")\n",
        "\n",
        "    # Select features (inputs) and targets (outputs)\n",
        "    input_features = [\n",
        "        'RSI', 'MACD', 'MACD_Signal', 'Momentum', 'OBV', 'ATR',\n",
        "        'EPS_Growth', 'Revenue_Growth', 'ROE'\n",
        "    ]\n",
        "    output_targets = ['RSI', 'MACD', 'close'] # 'close' here refers to the future close price\n",
        "\n",
        "    # Ensure all required columns exist after calculations and merges\n",
        "    missing_cols = [col for col in input_features + output_targets if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        print(f\"Error: Missing required columns in DataFrame: {missing_cols}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Normalize indicators\n",
        "    scaler_input = MinMaxScaler()\n",
        "    scaler_output = MinMaxScaler()\n",
        "\n",
        "    # Create input and output sequences\n",
        "    X, Y = [], []\n",
        "    # The range for `i` must ensure that `i + lookback_window + predict_horizon - 1`\n",
        "    # does not exceed the length of the DataFrame.\n",
        "    # The last valid index for `Y` will be `len(df) - 1`.\n",
        "    # So, `i + lookback_window + predict_horizon - 1 <= len(df) - 1`\n",
        "    # which simplifies to `i <= len(df) - lookback_window - predict_horizon`.\n",
        "    for i in range(len(df) - lookback_window - predict_horizon + 1):\n",
        "        # Input: `lookback_window` days of selected indicators\n",
        "        X.append(df[input_features].iloc[i : i + lookback_window].values)\n",
        "        # Output: `predict_horizon` day's RSI, MACD, and 'close' price\n",
        "        Y.append(df[output_targets].iloc[i + lookback_window + predict_horizon - 1].values)\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    if X.size == 0 or Y.size == 0:\n",
        "        print(f\"Not enough data after windowing with lookback_window={lookback_window} and predict_horizon={predict_horizon}.\")\n",
        "        print(\"Adjust lookback_window or predict_horizon, or ensure sufficient input data.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Apply scaling to input features\n",
        "    # Reshape X to (n_samples * lookback_window, n_features) for scaling\n",
        "    original_shape_X = X.shape\n",
        "    X_reshaped_for_scaling = X.reshape(-1, original_shape_X[-1])\n",
        "    X_scaled_reshaped = scaler_input.fit_transform(X_reshaped_for_scaling)\n",
        "    X_scaled = X_scaled_reshaped.reshape(original_shape_X)\n",
        "\n",
        "    # Apply scaling to output targets\n",
        "    Y_scaled = scaler_output.fit_transform(Y)\n",
        "\n",
        "    print(f\"Created X_scaled with shape: {X_scaled.shape}\")\n",
        "    print(f\"Created Y_scaled with shape: {Y_scaled.shape}\")\n",
        "\n",
        "    return X_scaled, Y_scaled, scaler_input, scaler_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 729,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Preparing DataFrame for AAPL for 80 quarters ---\n",
            "Fetching historical price data for AAPL from 2005-07-11 to 2025-07-11 from FMP API...\n",
            "Successfully fetched 5032 historical price records from FMP.\n",
            "Initial price_data shape: (5032, 5)\n",
            "DataFrame shape after technical indicator calculation: (5032, 11)\n",
            "DataFrame shape after dropping NaNs from indicator calculation: (5019, 11)\n",
            "Fetching fundamental data for AAPL from 2005-07-11 to 2025-07-11 from FMP API...\n",
            "Successfully fetched and processed 79 fundamental records from FMP.\n",
            "Fundamental data shape: (79, 3)\n",
            "===========================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 79 entries, 0 to 78\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   date            79 non-null     datetime64[ns]\n",
            " 1   Revenue_Growth  79 non-null     float64       \n",
            " 2   EPS_Growth      79 non-null     float64       \n",
            " 3   ROE             79 non-null     float64       \n",
            "dtypes: datetime64[ns](1), float64(3)\n",
            "memory usage: 2.6 KB\n",
            "None\n",
            "--------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5019 entries, 0 to 5018\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   date         5019 non-null   datetime64[ns]\n",
            " 1   open         5019 non-null   float64       \n",
            " 2   high         5019 non-null   float64       \n",
            " 3   low          5019 non-null   float64       \n",
            " 4   close        5019 non-null   float64       \n",
            " 5   volume       5019 non-null   int64         \n",
            " 6   RSI          5019 non-null   float64       \n",
            " 7   MACD         5019 non-null   float64       \n",
            " 8   MACD_Signal  5019 non-null   float64       \n",
            " 9   Momentum     5019 non-null   float64       \n",
            " 10  OBV          5019 non-null   float64       \n",
            " 11  ATR          5019 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(10), int64(1)\n",
            "memory usage: 470.7 KB\n",
            "None\n",
            "===========================\n",
            "\n",
            "DataFrame successfully saved to 'cache/AAPL_data_combined_data_2025-07-11.csv'\n",
            "\n",
            "DataFrame successfully saved to 'cache/AAPL_fundamental_data_combined_data_2025-07-11.csv'\n",
            "\n",
            "DataFrame successfully saved to 'cache/AAPL_merged_combined_data_2025-07-11.csv'\n",
            "DataFrame shape after left merge with fundamental data: (5098, 14)\n",
            "NaN count in fundamental columns after merge (before ffill):\n",
            "  EPS_Growth: 5019 NaNs\n",
            "  Revenue_Growth: 5019 NaNs\n",
            "  ROE: 5019 NaNs\n",
            "\n",
            "DataFrame successfully saved to 'cache/AAPL_merged_combined_data_2025-07-11.csv'\n",
            "DataFrame shape after forward-fill: (5057, 14)\n",
            "NaN count in fundamental columns after ffill (before final dropna):\n",
            "  EPS_Growth: 0 NaNs\n",
            "  Revenue_Growth: 0 NaNs\n",
            "  ROE: 0 NaNs\n",
            "DataFrame shape after dropping remaining NaNs: (5057, 14)\n",
            "DataFrame prepared with 5057 rows and 14 columns.\n",
            "DataFrame index name: date\n",
            "\n",
            "--- First few rows of Prepared DataFrame ---\n",
            "            open  high   low  close        volume        RSI      MACD  \\\n",
            "date                                                                     \n",
            "2005-09-24  1.86  1.91  1.85   1.90  5.585065e+08  75.510204  0.070582   \n",
            "2005-09-26  1.93  1.95  1.90   1.92  5.466215e+08  71.428571  0.072679   \n",
            "2005-09-27  1.93  1.94  1.91   1.91  3.417741e+08  69.767442  0.072695   \n",
            "2005-09-28  1.90  1.90  1.81   1.82  1.126688e+09  54.166667  0.064701   \n",
            "2005-09-29  1.83  1.88  1.81   1.87  6.372206e+08  54.166667  0.061688   \n",
            "\n",
            "            MACD_Signal  Momentum           OBV       ATR  Revenue_Growth  \\\n",
            "date                                                                        \n",
            "2005-09-24     0.065481      0.05  9.669141e+09  0.047883        0.565106   \n",
            "2005-09-26     0.066920      0.02  1.021576e+10  0.048165        0.565106   \n",
            "2005-09-27     0.068075     -0.01  9.873989e+09  0.045743        0.565106   \n",
            "2005-09-28     0.067400     -0.09  8.747300e+09  0.052978        0.565106   \n",
            "2005-09-29     0.066258      0.05  9.384521e+09  0.055247        0.565106   \n",
            "\n",
            "            EPS_Growth       ROE  \n",
            "date                              \n",
            "2005-09-24    2.816327  0.057889  \n",
            "2005-09-26    2.816327  0.057889  \n",
            "2005-09-27    2.816327  0.057889  \n",
            "2005-09-28    2.816327  0.057889  \n",
            "2005-09-29    2.816327  0.057889  \n",
            "\n",
            "--- Last few rows of Prepared DataFrame ---\n",
            "               open    high     low   close      volume        RSI      MACD  \\\n",
            "date                                                                           \n",
            "2025-07-03  212.150  214.65  211.81  213.55  34955836.0  74.801244  1.755523   \n",
            "2025-07-07  212.680  216.23  208.80  209.95  50229000.0  72.666219  2.001910   \n",
            "2025-07-08  210.100  211.43  208.45  210.01  42848928.0  70.792967  2.176921   \n",
            "2025-07-09  209.530  211.33  207.22  211.14  48749400.0  79.557590  2.379372   \n",
            "2025-07-10  210.505  213.48  210.12  212.41  43770740.0  79.811676  2.612183   \n",
            "\n",
            "            MACD_Signal  Momentum           OBV       ATR  Revenue_Growth  \\\n",
            "date                                                                        \n",
            "2025-07-03     0.027272      1.11  5.458622e+10  4.277798        0.050753   \n",
            "2025-07-07     0.422200     -3.60  5.453599e+10  4.698091        0.050753   \n",
            "2025-07-08     0.773144      0.06  5.457884e+10  4.469013        0.050753   \n",
            "2025-07-09     1.094390      1.13  5.462759e+10  4.421144        0.050753   \n",
            "2025-07-10     1.397948      1.27  5.467136e+10  4.279658        0.050753   \n",
            "\n",
            "            EPS_Growth      ROE  \n",
            "date                             \n",
            "2025-07-03    0.078431  0.37098  \n",
            "2025-07-07    0.078431  0.37098  \n",
            "2025-07-08    0.078431  0.37098  \n",
            "2025-07-09    0.078431  0.37098  \n",
            "2025-07-10    0.078431  0.37098  \n",
            "\n",
            "Prepared DataFrame shape: (5057, 14)\n",
            "\n",
            "--- Creating Training/Testing Datasets ---\n",
            "Created X_scaled with shape: (5027, 30, 9)\n",
            "Created Y_scaled with shape: (5027, 3)\n",
            "\n",
            "Successfully created scaled datasets and scalers.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    symbol_to_process = \"AAPL\" # Example symbol\n",
        "    desired_period_in_quarters = 80 # For 20 years of data (20 * 4 = 80 quarters)\n",
        "    # IMPORTANT: Replace \"YOUR_FMP_API_KEY\" with your actual FMP API key\n",
        "\n",
        "    # Step 1: Prepare the DataFrame\n",
        "    # Pass the API key to prepare_dataframe\n",
        "    prepared_df = prepare_dataframe(symbol_to_process, desired_period_in_quarters)\n",
        "\n",
        "    if prepared_df is not None:\n",
        "        print(\"\\n--- First few rows of Prepared DataFrame ---\")\n",
        "        print(prepared_df.head())\n",
        "        print(\"\\n--- Last few rows of Prepared DataFrame ---\")\n",
        "        print(prepared_df.tail())\n",
        "        print(f\"\\nPrepared DataFrame shape: {prepared_df.shape}\")\n",
        "\n",
        "        # Step 2: Create training and testing datasets\n",
        "        X_scaled, Y_scaled, scaler_input, scaler_output = create_training_testing_datasets(\n",
        "            prepared_df,\n",
        "            lookback_window=30,\n",
        "            predict_horizon=1\n",
        "        )\n",
        "\n",
        "        if X_scaled is not None:\n",
        "            print(\"\\nSuccessfully created scaled datasets and scalers.\")\n",
        "            # You can now proceed with splitting into train/test sets and model training\n",
        "            # from sklearn.model_selection import train_test_split\n",
        "            # X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_scaled, test_size=0.2, random_state=42)\n",
        "            # print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
        "            # print(f\"X_test shape: {X_test.shape}, Y_test shape: {Y_test.shape}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning-python-3.10_numpy1.26.4-M4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
